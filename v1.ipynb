{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Nauka pyTorch poprzez trening i Ocena Modeli na Zbiorze Danych Caltech101\n",
    "Ten notebook ma na celu przeprowadzenie treningu modelu niestandardowego i modelu ResNet-18 na zbiorze danych Caltech101 oraz ich ocenę. Ponadto, zostanie utworzony interfejs Gradio do interakcji z modelem ResNet-18.\n",
    "\n",
    "# Importowanie bibliotek\n",
    "Najpierw zaimportujemy wszystkie niezbędne biblioteki do przetwarzania obrazów, trenowania modeli, ładowania danych oraz interakcji z modelem za pomocą Gradio."
   ],
   "id": "32d939dca06a9d52"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-20T16:45:41.444757Z",
     "start_time": "2024-05-20T16:45:41.441697Z"
    }
   },
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import Caltech101\n",
    "from torchvision.models import resnet18\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import gradio as gr\n"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Definiowanie transformacji i ładowanie zbioru danych\n",
    "## Transformacje\n",
    "Definiujemy transformacje, które będą stosowane do obrazów wejściowych. Transformacje obejmują:\n",
    "\n",
    "- Resize: Zmiana rozmiaru obrazów do 224x224 pikseli.\n",
    "- Grayscale: Konwersja obrazów na 3-kanałowe obrazy w odcieniach szarości.\n",
    "- ToTensor: Konwersja obrazów do formatu tensora.\n",
    "- Normalize: Normalizacja obrazów z użyciem określonych średnich i odchyleń standardowych.\n",
    "## Ładowanie zbioru danych\n",
    "Ładujemy zbiór danych Caltech101 i dzielimy go na zestawy treningowe i walidacyjne w stosunku 80:20."
   ],
   "id": "749b4188663b475a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T17:35:39.541410Z",
     "start_time": "2024-05-20T17:35:39.531276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224\n",
    "    transforms.Grayscale(num_output_channels=3),  # Convert grayscale images to 3 channels\n",
    "    transforms.ToTensor(),  # Convert images to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize images\n",
    "])\n",
    "\n",
    "# Load the dataset\n",
    "dataset = Caltech101(root='./data', download=True, transform=transform)\n",
    "\n",
    "# Split dataset into training and validation sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
   ],
   "id": "ee491dae656bb62d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Definiowanie niestandardowego modelu CNN\n",
    "Tworzymy niestandardowy model CNN, który będzie wykorzystywany do klasyfikacji obrazów. Model ten składa się z:\n",
    "\n",
    "- Części ekstrakcji cech: Dwie warstwy konwolucyjne, każda z warstwą aktywacji ReLU i warstwą MaxPool.\n",
    "- Części klasyfikacji: Dwie warstwy w pełni połączone z warstwami Dropout i ReLU.\n",
    "python\n"
   ],
   "id": "4934724850b7bbb3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T17:35:40.443Z",
     "start_time": "2024-05-20T17:35:40.439029Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(128 * 56 * 56, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ],
   "id": "af789117c1f8df82",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Ładowanie modelu ResNet-18\n",
    "Załadujemy wstępnie wytrenowany model ResNet-18 i zmodyfikujemy jego ostatnią w pełni połączoną warstwę, aby dopasować ją do liczby klas w zbiorze danych Caltech101."
   ],
   "id": "819d76a795d8bd8b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T17:35:42.150574Z",
     "start_time": "2024-05-20T17:35:41.446493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the pre-trained ResNet-18 model\n",
    "resnet_model = resnet18(pretrained=True)\n",
    "\n",
    "# Modify the final fully connected layer to match the number of classes in Caltech101\n",
    "num_classes = len(dataset.categories)\n",
    "resnet_model.fc = nn.Linear(resnet_model.fc.in_features, num_classes)\n"
   ],
   "id": "cf7334fdb6659740",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Inicjalizacja niestandardowego modelu\n",
    "Inicjalizujemy niestandardowy model z odpowiednią liczbą kla"
   ],
   "id": "f352a340aefe58ed"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Initialize the custom model\n",
    "custom_model = CustomCNN(num_classes=num_classes)"
   ],
   "id": "5d56c8c2f333b725"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "c631ac53002acc9c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Definiowanie funkcji straty i optymalizatorów\n",
    "Zdefiniujemy funkcję straty (CrossEntropyLoss) oraz optymalizatory (SGD) dla obu modeli."
   ],
   "id": "c999666733107790"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define loss function and optimizer for both models\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "resnet_optimizer = optim.SGD(resnet_model.parameters(), lr=0.001, momentum=0.9)\n",
    "custom_optimizer = optim.SGD(custom_model.parameters(), lr=0.001, momentum=0.9)"
   ],
   "id": "928024ca63eb17b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Funkcja pętli trenowania\n",
    "Definiujemy funkcję pętli trenowania, która będzie:\n",
    "\n",
    "- Trenować model na zbiorze treningowym.\n",
    "- Obliczać stratę i dokładność na zbiorze treningowym.\n",
    "- Walidować model na zbiorze walidacyjnym.\n",
    "- Obliczać stratę i dokładność na zbiorze walidacyjnym.\n",
    "- Wyświetlać wyniki dla każdej epoki."
   ],
   "id": "e6eda292aebab562"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T17:37:39.604737Z",
     "start_time": "2024-05-20T17:37:39.594890Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training loop function\n",
    "def train_model(model, optimizer, num_epochs=5):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()  # Zero the parameter gradients\n",
    "            outputs = model(inputs)  # Forward pass\n",
    "            loss = criterion(outputs, labels)  # Compute loss\n",
    "            loss.backward()  # Backward pass\n",
    "            optimizer.step()  # Optimize the model\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_accuracy = 100 * correct / total\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_accuracy = 100 * val_correct / val_total\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], \"\n",
    "              f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, \"\n",
    "              f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "\n"
   ],
   "id": "74cd1338cf006c5c",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Trenowanie obu modeli\n",
    "Teraz przeprowadzimy trening obu modeli: niestandardowego modelu CNN oraz zmodyfikowanego ResNet-18."
   ],
   "id": "a1b941160971b3cc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T18:07:26.884036Z",
     "start_time": "2024-05-20T17:37:41.587933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train both models\n",
    "print(\"Training Custom Model:\")\n",
    "train_model(custom_model, custom_optimizer)\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(resnet_model.state_dict(), 'caltech101_resnet18.pth')\n",
    "\n"
   ],
   "id": "d3f6be0bb617f759",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Custom Model:\n",
      "Epoch [1/5], Train Loss: 3.7045, Train Accuracy: 24.55%, Validation Loss: 3.2122, Validation Accuracy: 31.39%\n",
      "Epoch [2/5], Train Loss: 3.2525, Train Accuracy: 31.03%, Validation Loss: 2.9720, Validation Accuracy: 37.44%\n",
      "Epoch [3/5], Train Loss: 2.9953, Train Accuracy: 34.99%, Validation Loss: 2.7649, Validation Accuracy: 41.42%\n",
      "Epoch [4/5], Train Loss: 2.7763, Train Accuracy: 38.55%, Validation Loss: 2.5976, Validation Accuracy: 44.41%\n",
      "Epoch [5/5], Train Loss: 2.5172, Train Accuracy: 42.67%, Validation Loss: 2.4280, Validation Accuracy: 47.12%\n"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"\\nTraining ResNet-18 Model:\")\n",
    "train_model(resnet_model, resnet_optimizer)\n",
    "# Save the trained model\n",
    "torch.save(resnet_model.state_dict(), 'caltech101_resnet18.pth')\n"
   ],
   "id": "20f12b163dc11a1e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Ładowanie modelu\n",
    "Ładujemy zapisany model ResNet-18 do stanu ewaluacji."
   ],
   "id": "e57e505cb449ffd5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load the saved model for inference\n",
    "model.load_state_dict(torch.load('caltech101_resnet18.pth'))\n",
    "model.eval()\n"
   ],
   "id": "86e69e3396e3182b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Tworzenie interfejsu Gradio do interakcji z modelem\n",
    "Ładujemy zapisany model ResNet-18, definiujemy funkcję predykcji i tworzymy interfejs Gradio.\n"
   ],
   "id": "c76c985550a3adbf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T17:22:56.444398Z",
     "start_time": "2024-05-20T17:22:56.224544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the prediction function\n",
    "def predict(im):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # Resize images to 224x224\n",
    "        transforms.Grayscale(num_output_channels=3),  # Convert grayscale images to 3 channels\n",
    "        transforms.ToTensor(),  # Convert images to tensor\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize images\n",
    "    ])\n",
    "    im = transform(im).unsqueeze(0)  # Transform and add batch dimension\n",
    "    with torch.no_grad():\n",
    "        output = model(im)  # Forward pass\n",
    "    output = torch.nn.functional.softmax(output[0], dim=0)  # Apply softmax\n",
    "    return {train_dataset.categories[i]: float(output[i]) for i in range(len(output))}\n",
    "\n",
    "\n",
    "# Create Gradio interface\n",
    "imagein = gr.Image(type='pil')\n",
    "label = gr.Label(num_top_classes=5)\n",
    "\n",
    "gr.Interface(fn=predict, inputs=imagein, outputs=label).launch()\n"
   ],
   "id": "10a550d87ddaba72",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "c4a1de92cb30b18f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
